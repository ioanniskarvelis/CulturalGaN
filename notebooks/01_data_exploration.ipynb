{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greek Motif Dataset Exploration\n",
    "\n",
    "This notebook explores the processed Greek traditional motif dataset:\n",
    "- Dataset statistics and distribution\n",
    "- Visual samples by region\n",
    "- Geometric feature analysis\n",
    "- Embedding visualization (if available)\n",
    "- Quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "metadata_path = project_root / \"data\" / \"processed\" / \"metadata.csv\"\n",
    "\n",
    "if metadata_path.exists():\n",
    "    df = pd.read_csv(metadata_path)\n",
    "    print(f\"✓ Loaded {len(df)} samples\")\n",
    "    print(f\"\\nColumns: {list(df.columns)}\")\n",
    "    df.head()\n",
    "else:\n",
    "    print(f\"❌ Metadata not found at {metadata_path}\")\n",
    "    print(\"Please run Phase 1 preprocessing first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset Overview:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total images: {len(df)}\")\n",
    "print(f\"Number of regions: {df['region'].nunique()}\")\n",
    "print(f\"Regions: {sorted(df['region'].unique())}\")\n",
    "print(\"\\nSample distribution by region:\")\n",
    "print(df['region'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize region distribution\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "region_counts = df['region'].value_counts()\n",
    "region_counts.plot(kind='bar', ax=ax, color='steelblue', edgecolor='black')\n",
    "\n",
    "ax.set_title('Sample Distribution by Region', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Region', fontsize=12)\n",
    "ax.set_ylabel('Number of Samples', fontsize=12)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add count labels on top of bars\n",
    "for i, v in enumerate(region_counts):\n",
    "    ax.text(i, v + 2, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Geometric Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if geometric features exist\n",
    "geometric_cols = ['vertical_symmetry', 'horizontal_symmetry', 'edge_density']\n",
    "has_geometric = all(col in df.columns for col in geometric_cols)\n",
    "\n",
    "if has_geometric:\n",
    "    print(\"Geometric Feature Statistics:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(df[geometric_cols].describe())\n",
    "else:\n",
    "    print(\"❌ Geometric features not found in metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_geometric:\n",
    "    # Plot geometric feature distributions\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "    # Vertical symmetry\n",
    "    axes[0].hist(df['vertical_symmetry'], bins=30, color='skyblue', edgecolor='black')\n",
    "    axes[0].set_title('Vertical Symmetry Distribution')\n",
    "    axes[0].set_xlabel('Symmetry Score')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "    # Horizontal symmetry\n",
    "    axes[1].hist(df['horizontal_symmetry'], bins=30, color='lightcoral', edgecolor='black')\n",
    "    axes[1].set_title('Horizontal Symmetry Distribution')\n",
    "    axes[1].set_xlabel('Symmetry Score')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "    # Edge density\n",
    "    axes[2].hist(df['edge_density'], bins=30, color='lightgreen', edgecolor='black')\n",
    "    axes[2].set_title('Edge Density Distribution')\n",
    "    axes[2].set_xlabel('Edge Density')\n",
    "    axes[2].set_ylabel('Frequency')\n",
    "    axes[2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visual Samples by Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples_by_region(region_name, n_samples=6):\n",
    "    \"\"\"\n",
    "    Display sample images from a specific region.\n",
    "    \"\"\"\n",
    "    region_df = df[df['region'] == region_name]\n",
    "\n",
    "    if len(region_df) == 0:\n",
    "        print(f\"No samples found for region: {region_name}\")\n",
    "        return\n",
    "\n",
    "    n_samples = min(n_samples, len(region_df))\n",
    "    samples = region_df.sample(n=n_samples, random_state=42)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, (_, row) in enumerate(samples.iterrows()):\n",
    "        if idx >= len(axes):\n",
    "            break\n",
    "\n",
    "        img_path = project_root / row['image_path']\n",
    "        if img_path.exists():\n",
    "            img = Image.open(img_path)\n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].axis('off')\n",
    "\n",
    "            # Add filename as title\n",
    "            axes[idx].set_title(row['filename'], fontsize=8)\n",
    "        else:\n",
    "            axes[idx].text(0.5, 0.5, 'Image not found', ha='center', va='center')\n",
    "            axes[idx].axis('off')\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for idx in range(n_samples, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "    fig.suptitle(f'Sample Motifs from {region_name} (n={len(region_df)} total)',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show samples from each region\n",
    "regions = sorted(df['region'].unique())\n",
    "print(f\"Showing samples from {len(regions)} regions...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display samples for each region (choose regions to explore)\n",
    "for region in regions[:3]:  # Show first 3 regions\n",
    "    show_samples_by_region(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Color Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_color_distribution(n_samples=100):\n",
    "    \"\"\"\n",
    "    Analyze color distribution across the dataset.\n",
    "    \"\"\"\n",
    "    samples = df.sample(n=min(n_samples, len(df)), random_state=42)\n",
    "\n",
    "    r_values, g_values, b_values = [], [], []\n",
    "\n",
    "    for _, row in samples.iterrows():\n",
    "        img_path = project_root / row['image_path']\n",
    "        if img_path.exists():\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_array = np.array(img)\n",
    "\n",
    "            # Average color per channel\n",
    "            r_values.append(img_array[:, :, 0].mean())\n",
    "            g_values.append(img_array[:, :, 1].mean())\n",
    "            b_values.append(img_array[:, :, 2].mean())\n",
    "\n",
    "    # Plot color distributions\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "    ax.hist(r_values, bins=30, alpha=0.5, label='Red', color='red', edgecolor='black')\n",
    "    ax.hist(g_values, bins=30, alpha=0.5, label='Green', color='green', edgecolor='black')\n",
    "    ax.hist(b_values, bins=30, alpha=0.5, label='Blue', color='blue', edgecolor='black')\n",
    "\n",
    "    ax.set_title(f'RGB Channel Distribution (n={len(samples)} samples)', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Average Pixel Value', fontsize=12)\n",
    "    ax.set_ylabel('Frequency', fontsize=12)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Color Statistics (n={len(samples)} samples):\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Red   - Mean: {np.mean(r_values):.2f}, Std: {np.std(r_values):.2f}\")\n",
    "    print(f\"Green - Mean: {np.mean(g_values):.2f}, Std: {np.std(g_values):.2f}\")\n",
    "    print(f\"Blue  - Mean: {np.mean(b_values):.2f}, Std: {np.std(b_values):.2f}\")\n",
    "\n",
    "analyze_color_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Embedding Exploration (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for embeddings\n",
    "embeddings_path = project_root / \"data\" / \"embeddings\" / \"embeddings.npz\"\n",
    "\n",
    "if embeddings_path.exists():\n",
    "    print(\"✓ Loading embeddings...\")\n",
    "    embeddings = np.load(embeddings_path)\n",
    "    print(f\"\\nAvailable embeddings: {list(embeddings.keys())}\")\n",
    "\n",
    "    for key in embeddings.keys():\n",
    "        print(f\"  {key}: shape = {embeddings[key].shape}\")\n",
    "\n",
    "    HAS_EMBEDDINGS = True\n",
    "else:\n",
    "    print(\"❌ Embeddings not found. Run Phase 2 to create embeddings.\")\n",
    "    HAS_EMBEDDINGS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_EMBEDDINGS:\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.manifold import TSNE\n",
    "\n",
    "    # Use combined embeddings for visualization\n",
    "    combined_emb = embeddings['combined']\n",
    "    print(f\"Combined embedding shape: {combined_emb.shape}\")\n",
    "\n",
    "    # Load embedding metadata to get region labels\n",
    "    emb_metadata_path = project_root / \"data\" / \"embeddings\" / \"embeddings_metadata.csv\"\n",
    "    if emb_metadata_path.exists():\n",
    "        emb_df = pd.read_csv(emb_metadata_path)\n",
    "\n",
    "        # PCA visualization\n",
    "        print(\"\\nRunning PCA...\")\n",
    "        pca = PCA(n_components=2)\n",
    "        pca_result = pca.fit_transform(combined_emb)\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "\n",
    "        # Plot by region\n",
    "        for region in emb_df['region'].unique():\n",
    "            mask = emb_df['region'] == region\n",
    "            ax.scatter(pca_result[mask, 0], pca_result[mask, 1],\n",
    "                      label=region, alpha=0.6, s=50)\n",
    "\n",
    "        ax.set_title('PCA Projection of Combined Embeddings', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)', fontsize=12)\n",
    "        ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)', fontsize=12)\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        ax.grid(alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"\\nPCA Explained Variance:\")\n",
    "        print(f\"  PC1: {pca.explained_variance_ratio_[0]:.2%}\")\n",
    "        print(f\"  PC2: {pca.explained_variance_ratio_[1]:.2%}\")\n",
    "        print(f\"  Total: {pca.explained_variance_ratio_[:2].sum():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Quality Checks:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n1. Missing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() == 0:\n",
    "    print(\"  ✓ No missing values found\")\n",
    "else:\n",
    "    print(\"  ❌ Missing values detected:\")\n",
    "    print(missing[missing > 0])\n",
    "\n",
    "# Check for duplicate filenames\n",
    "print(\"\\n2. Duplicate Filenames:\")\n",
    "duplicates = df['filename'].duplicated().sum()\n",
    "if duplicates == 0:\n",
    "    print(\"  ✓ No duplicate filenames\")\n",
    "else:\n",
    "    print(f\"  ❌ {duplicates} duplicate filenames found\")\n",
    "\n",
    "# Check image file existence\n",
    "print(\"\\n3. Image File Existence:\")\n",
    "missing_files = 0\n",
    "for _, row in df.iterrows():\n",
    "    img_path = project_root / row['image_path']\n",
    "    if not img_path.exists():\n",
    "        missing_files += 1\n",
    "\n",
    "if missing_files == 0:\n",
    "    print(f\"  ✓ All {len(df)} image files found\")\n",
    "else:\n",
    "    print(f\"  ❌ {missing_files} image files not found\")\n",
    "\n",
    "# Check image dimensions\n",
    "print(\"\\n4. Image Dimensions (sampling 20 images):\")\n",
    "sample_dims = []\n",
    "for _, row in df.sample(n=min(20, len(df)), random_state=42).iterrows():\n",
    "    img_path = project_root / row['image_path']\n",
    "    if img_path.exists():\n",
    "        img = Image.open(img_path)\n",
    "        sample_dims.append(img.size)\n",
    "\n",
    "if len(sample_dims) > 0:\n",
    "    unique_dims = set(sample_dims)\n",
    "    print(f\"  Found {len(unique_dims)} unique dimensions:\")\n",
    "    for dim in unique_dims:\n",
    "        count = sample_dims.count(dim)\n",
    "        print(f\"    {dim[0]}x{dim[1]}: {count} images\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"✓ Data quality check complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Summary:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Number of regions: {df['region'].nunique()}\")\n",
    "print(f\"\\nRegion with most samples: {df['region'].value_counts().index[0]} ({df['region'].value_counts().iloc[0]} samples)\")\n",
    "print(f\"Region with least samples: {df['region'].value_counts().index[-1]} ({df['region'].value_counts().iloc[-1]} samples)\")\n",
    "\n",
    "# Check if dataset is balanced\n",
    "max_count = df['region'].value_counts().iloc[0]\n",
    "min_count = df['region'].value_counts().iloc[-1]\n",
    "imbalance_ratio = max_count / min_count\n",
    "\n",
    "print(f\"\\nClass imbalance ratio: {imbalance_ratio:.2f}x\")\n",
    "if imbalance_ratio > 3:\n",
    "    print(\"  ⚠️  High class imbalance detected. Consider:\")\n",
    "    print(\"     - Using weighted sampling during training\")\n",
    "    print(\"     - Data augmentation for under-represented regions\")\n",
    "else:\n",
    "    print(\"  ✓ Dataset is reasonably balanced\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Ready to proceed with training!\")\n",
    "print(\"Next steps:\")\n",
    "print(\"  1. Run Phase 2 (symbolic analysis) if not done yet\")\n",
    "print(\"  2. Check training configuration in configs/stylegan3_greek_simple.yaml\")\n",
    "print(\"  3. Start training with: python scripts/train_gan.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
